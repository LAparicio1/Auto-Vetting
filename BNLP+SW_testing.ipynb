{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c75d04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "07290186",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = random.randint(0, 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b960defd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upper abdomen pain content worse after certain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recurrent upper abdomen pain after eating no b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upper abdomen fullness with bloating did have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recurrent episode of abdominal pain cause gall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recurrent raised ggt obesity fatty infiltration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>gallbladder polyp umm check for growth december</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>aml on the left check size please in 12 month</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>eye melanoma need abdomen check every 12 month...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>aortic aneurism measured umm in 2022 please re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>liver cyst seen on ut scan report suggested ev...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  y\n",
       "0    upper abdomen pain content worse after certain...  1\n",
       "1    recurrent upper abdomen pain after eating no b...  1\n",
       "2    upper abdomen fullness with bloating did have ...  1\n",
       "3    recurrent episode of abdominal pain cause gall...  1\n",
       "4      recurrent raised ggt obesity fatty infiltration  1\n",
       "..                                                 ... ..\n",
       "225    gallbladder polyp umm check for growth december  2\n",
       "226      aml on the left check size please in 12 month  2\n",
       "227  eye melanoma need abdomen check every 12 month...  2\n",
       "228  aortic aneurism measured umm in 2022 please re...  2\n",
       "229  liver cyst seen on ut scan report suggested ev...  2\n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd68bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1d56d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sentences = df['Sentence'].to_list()\n",
    "\n",
    "tokens = [nltk.word_tokenize(word) for word in sentences]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = []\n",
    "for sentence in tokens:\n",
    "    filtered_word = [word for word in sentence if word not in stop_words]\n",
    "    filtered_tokens.append(filtered_word)\n",
    "\n",
    "non_stop = [' '.join(words) for words in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3cbb02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = non_stop\n",
    "y = df['y'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed94d04",
   "metadata": {},
   "source": [
    "### BOW + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bbccec78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 768 candidates, totalling 2304 fits\n",
      "Best Hyperparameters: {'C': 0.1, 'coef0': 0.0, 'degree': 1, 'gamma': 'scale', 'kernel': 'linear', 'probability': True, 'shrinking': True}\n",
      "Accuracy: 0.8529411764705882\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85        15\n",
      "           1       0.67      0.89      0.76         9\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.86      0.87      0.85        34\n",
      "weighted avg       0.89      0.85      0.86        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X_list)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'degree': [1, 2, 3, 4],\n",
    "    'coef0': [0.0, 1.0],\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True, False],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_svc = SVC(**best_params)\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_svc.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0538985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           2      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_svc.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2bf47270",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([{'Model': 'BOW + SVC', 'Accuracy': final_score*100}])\n",
    "results = results.set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef0777",
   "metadata": {},
   "source": [
    "### BOW + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e40e033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.8235294117647058\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        15\n",
      "           1       0.62      0.89      0.73         9\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.84      0.85      0.83        34\n",
      "weighted avg       0.87      0.82      0.83        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "07aa3775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           2      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_rf.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['BOW + RF'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1a6ba",
   "metadata": {},
   "source": [
    "### BOW + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f72e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Hyperparameters: {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.8529411764705882\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85        15\n",
      "           1       0.67      0.89      0.76         9\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.86      0.87      0.85        34\n",
      "weighted avg       0.89      0.85      0.86        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_logreg = LogisticRegression(**best_params)\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_logreg.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "663551c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           1      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_logreg.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['BOW + LogReg'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f71f5",
   "metadata": {},
   "source": [
    "### BOW + XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8c9882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73c40386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.7647058823529411\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        15\n",
      "           1       0.54      0.78      0.64         9\n",
      "           2       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.78      0.77      0.76        34\n",
      "weighted avg       0.81      0.76      0.78        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"C\", \"max_iter\", \"penalty\", \"solver\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "best_xgb = XGBClassifier(**best_params)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_xgb.predict(X_val)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b49d17ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           1      2\n",
      "2           1      1\n",
      "3           1      1\n",
      "4           1      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          2      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          1      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          0      0\n",
      "0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_xgb.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['BOW + XGBoost'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef6525fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Best Hyperparameters: {'C': 1, 'coef0': 0.0, 'degree': 2, 'gamma': 'scale', 'kernel': 'linear', 'probability': True, 'shrinking': True}\n",
      "Accuracy: 0.7941176470588235\n",
      "Classification Report:\n",
      "<function classification_report at 0x000001D41A736950>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_X = tfidf_vectorizer.fit_transform(X_list)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(tfidf_X, y, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 1.0],\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True, False],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_svc = SVC(**best_params)\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_svc.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{classification_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ffe09149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           2      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          1      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          2      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_svc.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['TF-IDF + SVC'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bcd2b8",
   "metadata": {},
   "source": [
    "### TF-IDF + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d6cf2832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.7647058823529411\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72        15\n",
      "           1       0.54      0.78      0.64         9\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.78      0.79      0.77        34\n",
      "weighted avg       0.81      0.76      0.77        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2339305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           2      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8285714285714286\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_rf.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['TF-IDF + RF'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5e322",
   "metadata": {},
   "source": [
    "###  TF-IDF + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2d7cfe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best Hyperparameters: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8235294117647058\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        15\n",
      "           1       0.62      0.89      0.73         9\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.84      0.85      0.83        34\n",
      "weighted avg       0.87      0.82      0.83        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "logreg_classifier = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_logreg = LogisticRegression(**best_params)\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_logreg.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "391fa347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           2      2\n",
      "2           2      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          1      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          1      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_logreg.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['TF-IDF + LogReg'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e00c1",
   "metadata": {},
   "source": [
    "### TF-IDF + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed34bfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        15\n",
      "           1       0.43      0.67      0.52         9\n",
      "           2       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.65        34\n",
      "   macro avg       0.68      0.66      0.66        34\n",
      "weighted avg       0.70      0.65      0.66        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:34:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"C\", \"max_iter\", \"penalty\", \"solver\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "best_xgb = XGBClassifier(**best_params)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_xgb.predict(X_val)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5eba613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicton  Label\n",
      "0           1      1\n",
      "1           1      2\n",
      "2           1      1\n",
      "3           1      1\n",
      "4           0      0\n",
      "5           2      2\n",
      "6           2      2\n",
      "7           2      2\n",
      "8           2      2\n",
      "9           0      0\n",
      "10          1      1\n",
      "11          2      2\n",
      "12          1      1\n",
      "13          1      1\n",
      "14          0      0\n",
      "15          1      1\n",
      "16          2      2\n",
      "17          2      2\n",
      "18          2      2\n",
      "19          0      0\n",
      "20          2      2\n",
      "21          1      0\n",
      "22          2      2\n",
      "23          1      2\n",
      "24          1      1\n",
      "25          1      1\n",
      "26          1      0\n",
      "27          0      0\n",
      "28          2      2\n",
      "29          1      1\n",
      "30          0      0\n",
      "31          2      2\n",
      "32          1      1\n",
      "33          0      0\n",
      "34          1      0\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_xgb.predict(X_test)\n",
    "dataframe = pd.DataFrame({'Predicton' : test_pred, 'Label': y_test})\n",
    "print(dataframe)\n",
    "score = 0\n",
    "for i in range(len(y_test)):\n",
    "    if test_pred[i] == y_test[i]:\n",
    "        score += 1\n",
    "final_score = score / len(y_test)\n",
    "print(final_score)\n",
    "\n",
    "results.loc['TF-IDF + XGBoost'] = [final_score*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefde753",
   "metadata": {},
   "source": [
    "### Bert Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "185ac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer,  AutoModel\n",
    "\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_list, y, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=40):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "        return item\n",
    "\n",
    "class TextClassificationDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_texts, train_labels, val_texts, val_labels, test_texts, test_labels, tokenizer, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.train_texts = train_texts\n",
    "        self.train_labels = train_labels\n",
    "        self.val_texts = val_texts\n",
    "        self.val_labels = val_labels\n",
    "        self.test_texts = test_texts\n",
    "        self.test_labels = test_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TextClassificationDataset(self.train_texts, self.train_labels, self.tokenizer)\n",
    "        self.val_dataset = TextClassificationDataset(self.val_texts, self.val_labels, self.tokenizer)\n",
    "        self.test_dataset = TextClassificationDataset(self.test_texts, self.test_labels, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "    \n",
    "\n",
    "class TextClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_classes, weight_decay=1e-5, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.model.get_input_embeddings()(input_ids)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return self.model(input_ids, attention_mask=attention_mask).logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.loss(logits, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.loss(logits, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = self.loss(logits, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        return F.cross_entropy(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e9245e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at medicalai/ClinicalBERT and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                                | Params\n",
      "----------------------------------------------------------------\n",
      "0 | model   | DistilBertForSequenceClassification | 135 M \n",
      "1 | dropout | Dropout                             | 0     \n",
      "----------------------------------------------------------------\n",
      "135 M     Trainable params\n",
      "0         Non-trainable params\n",
      "135 M     Total params\n",
      "541.308   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:281: PossibleUserWarning: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a684bc60d0c41f2a21343b6e2f28058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=13` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70deccf936a46c09e2a41a7af508a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5570173859596252     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5570173859596252    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5570173859596252}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "train_texts, train_labels = X_train, y_train  # Load your training data\n",
    "val_texts, val_labels = X_val, y_val  # Load your validation data\n",
    "test_texts, test_labels = X_test, y_test  # Load your test data\n",
    "\n",
    "# Create DataModule\n",
    "data_module = TextClassificationDataModule(train_texts, train_labels, val_texts, val_labels, test_texts, test_labels, tokenizer)\n",
    "\n",
    "# Create the model\n",
    "model = TextClassifier(\"medicalai/ClinicalBERT\", num_classes=3, weight_decay=1e-5, dropout_prob=0.3)\n",
    "\n",
    "# Create the trainer\n",
    "trainer = pl.Trainer(max_epochs=13, accelerator='cuda')\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "80bff3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.6426090038993264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in data_module.test_dataloader():\n",
    "    input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "    logits = model(input_ids, attention_mask)\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    all_predictions.extend(predicted_labels.tolist())\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1}')\n",
    "\n",
    "wrong_idx = []\n",
    "for i in range(len(all_predictions)):\n",
    "    if all_predictions[i] != all_labels[i]:\n",
    "        wrong_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8baf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ((len(all_labels) - len(wrong_idx)) / (len(all_labels))) * 100\n",
    "results.loc['Bert Medical'] = [accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc5e8f",
   "metadata": {},
   "source": [
    "### Bert base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4a224928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                          | Params\n",
      "----------------------------------------------------------\n",
      "0 | model   | BertForSequenceClassification | 109 M \n",
      "1 | dropout | Dropout                       | 0     \n",
      "----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.938   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:281: PossibleUserWarning: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c1367efc174bb6a222ca22cfdcbce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=13` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\LPA\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f41ba490284929a4589a192858d50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5785688161849976     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5785688161849976    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5785688161849976}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_texts, train_labels = X_train, y_train  # Load your training data\n",
    "val_texts, val_labels = X_val, y_val  # Load your validation data\n",
    "test_texts, test_labels = X_test, y_test  # Load your test data\n",
    "\n",
    "# Create DataModule\n",
    "data_module = TextClassificationDataModule(train_texts, train_labels, val_texts, val_labels, test_texts, test_labels, tokenizer)\n",
    "\n",
    "# Create the model\n",
    "model = TextClassifier(\"bert-base-uncased\", num_classes=3, weight_decay=1e-5, dropout_prob=0.3)\n",
    "\n",
    "# Create the trainer\n",
    "trainer = pl.Trainer(max_epochs=13, accelerator='cuda')\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, data_module)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72ba9e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.8179894179894179\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in data_module.test_dataloader():\n",
    "    input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "    logits = model(input_ids, attention_mask)\n",
    "    predicted_labels = torch.argmax(logits, dim=1)\n",
    "    all_predictions.extend(predicted_labels.tolist())\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1}')\n",
    "\n",
    "wrong_idx = []\n",
    "for i in range(len(all_predictions)):\n",
    "    if all_predictions[i] != all_labels[i]:\n",
    "        wrong_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "092a2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = ((len(all_labels) - len(wrong_idx)) / (len(all_labels))) * 100\n",
    "results.loc['Bert Base'] = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e69e5b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOW + SVC</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW + RF</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW + LogReg</th>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW + XGBoost</th>\n",
       "      <td>77.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF + SVC</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF + RF</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF + LogReg</th>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF + XGBoost</th>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Medical</th>\n",
       "      <td>68.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bert Base</th>\n",
       "      <td>82.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy\n",
       "Model                      \n",
       "BOW + SVC         82.857143\n",
       "BOW + RF          82.857143\n",
       "BOW + LogReg      85.714286\n",
       "BOW + XGBoost     77.142857\n",
       "TF-IDF + SVC      82.857143\n",
       "TF-IDF + RF       82.857143\n",
       "TF-IDF + LogReg   80.000000\n",
       "TF-IDF + XGBoost  85.714286\n",
       "Bert Medical      68.571429\n",
       "Bert Base         82.857143"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
